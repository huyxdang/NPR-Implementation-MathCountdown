"""Countdown task-specific logic: prompts, reward function, and validation."""

import re
from typing import Dict, List
from datasets import load_dataset
from transformers import AutoTokenizer


# Countdown task prompt template
TEMPLATE = """Using the numbers {numbers}, create an equation that equals {target}. 
You can use basic arithmetic operations (+, -, *, /) and each number can only be used once.
Show your reasoning in <think> </think> tags. And return the final equation in <answer> </answer> tags. Keep your reasoning under {max_tokens} tokens.
For example, numbers = [1, 2, 3, 4] and target = 5, the answer is <answer>(1 + 2) * 3 - 4</answer>."""


def _extract_answer(solution_str: str) -> str | None:
    """
    Extract the content from the last <answer>...</answer> tag in the given string.
    
    Args:
        solution_str: The full text generated by the model.
    
    Returns:
        The stripped string content of the last answer tag, or None if no tag is found.
    """
    if not solution_str:
        return None
    matches = list(re.finditer(r"<answer>\s*(.*?)\s*</answer>", solution_str, flags=re.DOTALL | re.IGNORECASE))
    return matches[-1].group(1).strip() if matches else None


def _validate_numbers(equation_str: str, available_numbers: List[int]) -> bool:
    """
    Check if the numbers used in the equation are exactly the ones available.
    
    Args:
        equation_str: The equation string to validate.
        available_numbers: A list of integers that are allowed to be used.
    
    Returns:
        True if the equation uses the correct numbers, False otherwise.
    """
    try: 
        # Extract all numbers from the equation 
        found_numbers = re.findall(r"\d+", equation_str)
        
        # Convert them into integers
        str_found_numbers = list(map(int, found_numbers))
        
        # Compare (check for number & frequency - since each number must only appear once)
        return sorted(str_found_numbers) == sorted(available_numbers)
        
    except Exception:
        return False


def _evaluate_equation(equation_str: str) -> float | None:
    """
    Safely evaluate a mathematical equation string.
    
    Args:
        equation_str: The equation string to evaluate.
    
    Returns:
        The result of the equation as a float, or None if it's invalid or unsafe.
    """
    try: 
        # Allows only valid characters
        if not re.fullmatch(r"[0-9+\-*/()\s]+", equation_str): 
            return None
        
        # Evaluate
        result = eval(equation_str, {"__builtins__": None}, {})

        # Return as float
        return float(result)
        
    except Exception:
        return None


def reward_fn(generated_text: str, ground_truth: Dict, scale_factor: float = 1.0) -> float:
    """
    Binary verifiable reward for Countdown:
    +1.0 if equation valid + uses exactly the given numbers + equals target,
    -1.0 otherwise.
    
    Args:
        generated_text: The model-generated response.
        ground_truth: Dictionary containing 'target' and 'numbers'/'nums'.
        scale_factor: Unused, kept for compatibility.
    
    Returns:
        +1.0 for correct solutions, -1.0 otherwise.
    """
    target = ground_truth.get("target")
    numbers = ground_truth.get("numbers", []) or ground_truth.get("nums", [])

    eq = _extract_answer(generated_text)
    if eq is None:
        return -1.0

    if not _validate_numbers(eq, numbers):
        return -1.0

    val = _evaluate_equation(eq)
    if val is None:
        return -1.0

    return 1.0 if abs(val - target) < 1e-6 else -1.0


def load_countdown_dataset(split: str, tokenizer: AutoTokenizer, max_tokens: int) -> List[Dict]:
    """
    Load and preprocess the Countdown dataset.
    
    Args:
        split: Dataset split ("train" or "test").
        tokenizer: Tokenizer to apply chat template.
        max_tokens: Max tokens for the prompt template.
    
    Returns:
        List of dictionaries with 'prompt' and 'answer' keys.
    """
    dataset = load_dataset("justinphan3110/Countdown-Tasks-3to4", split=split)
    
    examples = []
    for ex in dataset:
        prompt = TEMPLATE.format(numbers=ex["nums"], target=ex["target"], max_tokens=max_tokens)
        prompt = tokenizer.apply_chat_template(
            [dict(role="system", content="You are a helpful assistant."),
             dict(role="user", content=prompt)],
            add_generation_prompt=True, 
            tokenize=False
        )
        examples.append({
            "prompt": prompt,
            "answer": {"target": ex["target"], "numbers": ex["nums"]},
        })
    
    return examples

